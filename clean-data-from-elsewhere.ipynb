{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up data which was downloaded from elsewhere\n",
    "\n",
    "We've downloaded a data set from somewhere, but it doesn't come in a format that lets us easily bring it into Jupyter Notebook and Pandas to work with it.\n",
    "\n",
    "This notebook covers working with some **json** data to convert it to **CSV** which we can then load into a DataFrame and play with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we're going to do some experimenting with loading in the original data, before getting ot a point where we can put our earlier code into a function and run it that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = []\n",
    "with open(\"aquatics_centre.json\", \"r\") as the_file:\n",
    "    for line in the_file:\n",
    "        line = line.strip()\n",
    "        my_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data we can see that it is a set of key value pairs, as strings, inside a list."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We're going to loop through the data and remove the empty lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stripped_data = []\n",
    "for line in my_data:\n",
    "    if line != '[]':\n",
    "        stripped_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually do both of the previous steps together as we import the data, line by line strip out the empty lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_data = []\n",
    "with open(\"aquatics_centre.json\", \"r\") as the_file:\n",
    "    for line in the_file:\n",
    "        line = line.strip()\n",
    "        if line != '[]':\n",
    "            my_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still don't have json values though, as we currently have strings which parse to lists, due to the square brackets in them, so we need to remove the square brackets from each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = []\n",
    "for thing in my_data:\n",
    "    thing = thing.replace(\"[\", \"\")\n",
    "    thing = thing.replace(\"]\", \"\")\n",
    "    some_data.append(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we can just add this to the original code which imports the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_data = []\n",
    "with open(\"aquatics_centre.json\", \"r\") as the_file:\n",
    "    for line in the_file:\n",
    "        line = line.strip()\n",
    "        if line != '[]':\n",
    "            line = line.replace(\"[\", \"\")\n",
    "            line = line.replace(\"]\", \"\")\n",
    "            my_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want to do now is to take each of these lines and output them to a CSV file, in order to do this we need to use the json library we imported at the start, which lets us access the values in the key-value pairs. Although we could actually just include the **parsed[\"time\"]** and **parsed[\"value\"]** in the final line, we're actually pulling them out into variables so that you can see what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"aquatics.csv\", \"w\") as the_file:\n",
    "    the_file.write(\"timestamp, spaces \\n\")\n",
    "    for thing in my_data:\n",
    "        parsed = json.loads(thing)\n",
    "        time = parsed[\"time\"]\n",
    "        value = parsed[\"value\"]\n",
    "        the_file.write(time + \", \" + value + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the csv file and you'll notice that we have issues with the comma after the day part of the date being treated as a separator in the CSV file and making the program think that there are 3 coulmns of data. We need to run some code in a new version of the above cell to strip this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"aquatics.csv\", \"w\") as the_file:\n",
    "    the_file.write(\"timestamp, spaces \\n\")\n",
    "    for thing in my_data:\n",
    "        parsed = json.loads(thing)\n",
    "        time = parsed[\"time\"]\n",
    "        time = time.replace(\",\", \"\")\n",
    "        value = parsed[\"value\"]\n",
    "        the_file.write(time + \", \" + value + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the above cell and reopen the CSV file to look at the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're actually going to change the format of the timestamp as well, in order to make it slightly more friendly for when we do stuff with it later. So modify the above code again to make it output the timestamp like this: **2017-10-29 10:56**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"aquatics.csv\", \"w\") as the_file:\n",
    "    the_file.write(\"timestamp, spaces \\n\")\n",
    "    for thing in my_data:\n",
    "        parsed = json.loads(thing)\n",
    "        time = parsed[\"time\"]\n",
    "        time = time.replace(\",\", \"\")\n",
    "        time = \"2017-10-\" + time[4:6] + \" \" + time[16:24]\n",
    "        value = parsed[\"value\"]\n",
    "        the_file.write(time + \", \" + value + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now going to turn the parts we've done into a single function, that we can then call by passing in names for the input and output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_csv(input_file, output_file):\n",
    "    my_data = []\n",
    "    with open(input_file, \"r\") as the_file:\n",
    "        for line in the_file:\n",
    "            line = line.strip()\n",
    "            if line != '[]':\n",
    "                line = line.replace(\"[\", \"\")\n",
    "                line = line.replace(\"]\", \"\")\n",
    "                my_data.append(line)\n",
    "\n",
    "    with open(output_file, \"w\") as the_file:\n",
    "        the_file.write(\"timestamp, spaces \\n\")\n",
    "        for thing in my_data:\n",
    "            parsed = json.loads(thing)\n",
    "            time = parsed[\"time\"]\n",
    "            time = time.replace(\",\", \"\")\n",
    "            time = \"2017-10-\" + time[4:6] + \" \" + time[16:24]\n",
    "            value = parsed[\"value\"]\n",
    "            the_file.write(time + \", \" + value + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can call it for the two json files to create two csv files we can work with later on.\n",
    "\n",
    "**We could in theory just read in the json files and use the data directly from them in our code, but we're trying to show the multiple steps we go through to get to usable data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv(\"aquatics_centre.json\", \"aquatics.csv\")\n",
    "create_csv(\"sackville_street.json\", \"sackville.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
